{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "def read_img(source_path:str, source_type:str):\n",
    "    if source_type == \"image\":\n",
    "        return cv2.imread(source_path)\n",
    "\n",
    "def preprocessing(img, input_size:tuple =(640, 640)):\n",
    "    \n",
    "    if img.shape[0] != input_size[0] or img.shape[1] != input_size[1]:\n",
    "        input_img_resized = cv2.resize(img, input_size)\n",
    "    \n",
    "    input_img_rgb = cv2.cvtColor(input_img_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_img_normalized = input_img_rgb / 255.0\n",
    "\n",
    "    input_tensor = input_img_normalized.transpose(2, 0, 1).astype(np.float32)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "def load_model(model_path:str):\n",
    "    return ort.InferenceSession(model_path)\n",
    "\n",
    "def post_process(outputs):\n",
    "    # Example post-processing code, adjust according to your model's output format\n",
    "    boxes, scores, class_ids = outputs  # Split the output tensors if necessary\n",
    "\n",
    "    # Thresholding and NMS to remove unnecessary boxes\n",
    "    threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, threshold, nms_threshold)\n",
    "\n",
    "    # Extract the detected objects\n",
    "    detected_objects = []\n",
    "    for i in indices:\n",
    "        box = boxes[i[0]]\n",
    "        score = scores[i[0]]\n",
    "        class_id = class_ids[i[0]]\n",
    "        detected_objects.append((box, score, class_id))\n",
    "    \n",
    "    return detected_objects\n",
    "\n",
    "def visulize_objects(input_image, detected_objects):\n",
    "    # Draw the bounding boxes on the image\n",
    "    for box, score, class_id in detected_objects:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(input_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        label = f'{class_id}: {score:.2f}'\n",
    "        cv2.putText(input_image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('Detected Objects', input_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 0.1678469181060791\n",
      "FPS: 5.957809719020285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "source_path = r\"C:\\Users\\p.alishah\\Desktop\\Projects\\python\\models\\ultralytics\\data\\test\\val_all_data-56-_jpg.rf.fd1cd988f8460e5e0f2f51399df2c348.jpg\"\n",
    "model_path = r\"C:\\Users\\p.alishah\\Desktop\\Projects\\python\\models\\ultralytics\\runs\\detect\\train8\\weights\\best.onnx\"\n",
    "\n",
    "input_img = read_img(source_path, \"image\")\n",
    "preprocessed_img = preprocessing(input_img.copy())\n",
    "\n",
    "ort_session = load_model(model_path)\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = ort_session.run(None, {'images': preprocessed_img})\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Latency:\", (end_time - start_time))\n",
    "print(\"FPS:\", 1/(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(input_image, output):\n",
    "    \"\"\"\n",
    "    Performs post-processing on the model's output to extract bounding boxes, scores, and class IDs.\n",
    "\n",
    "    Args:\n",
    "        input_image (numpy.ndarray): The input image.\n",
    "        output (numpy.ndarray): The output of the model.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The input image with detections drawn on it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transpose and squeeze the output to match the expected shape\n",
    "    outputs = np.transpose(np.squeeze(output[0]))\n",
    "\n",
    "    # Get the number of rows in the outputs array\n",
    "    rows = outputs.shape[0]\n",
    "\n",
    "    # Lists to store the bounding boxes, scores, and class IDs of the detections\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Calculate the scaling factors for the bounding box coordinates\n",
    "    x_factor = self.img_width / self.input_width\n",
    "    y_factor = self.img_height / self.input_height\n",
    "\n",
    "    # Iterate over each row in the outputs array\n",
    "    for i in range(rows):\n",
    "        # Extract the class scores from the current row\n",
    "        classes_scores = outputs[i][4:]\n",
    "\n",
    "        # Find the maximum score among the class scores\n",
    "        max_score = np.amax(classes_scores)\n",
    "\n",
    "        # If the maximum score is above the confidence threshold\n",
    "        if max_score >= self.confidence_thres:\n",
    "            # Get the class ID with the highest score\n",
    "            class_id = np.argmax(classes_scores)\n",
    "\n",
    "            # Extract the bounding box coordinates from the current row\n",
    "            x, y, w, h = outputs[i][0], outputs[i][1], outputs[i][2], outputs[i][3]\n",
    "\n",
    "            # Calculate the scaled coordinates of the bounding box\n",
    "            left = int((x - w / 2) * x_factor)\n",
    "            top = int((y - h / 2) * y_factor)\n",
    "            width = int(w * x_factor)\n",
    "            height = int(h * y_factor)\n",
    "\n",
    "            # Add the class ID, score, and box coordinates to the respective lists\n",
    "            class_ids.append(class_id)\n",
    "            scores.append(max_score)\n",
    "            boxes.append([left, top, width, height])\n",
    "\n",
    "    # Apply non-maximum suppression to filter out overlapping bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, self.confidence_thres, self.iou_thres)\n",
    "\n",
    "    # Iterate over the selected indices after non-maximum suppression\n",
    "    for i in indices:\n",
    "        # Get the box, score, and class ID corresponding to the index\n",
    "        box = boxes[i]\n",
    "        score = scores[i]\n",
    "        class_id = class_ids[i]\n",
    "\n",
    "        # Draw the detection on the input image\n",
    "        self.draw_detections(input_image, box, score, class_id)\n",
    "\n",
    "    # Return the modified input image\n",
    "    return input_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
