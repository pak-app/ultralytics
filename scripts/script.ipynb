{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "def read_img(source_path:str):\n",
    "    return cv2.imread(source_path)\n",
    "\n",
    "def preprocessing(img, input_size:tuple =(640, 640)):\n",
    "    \n",
    "    if img.shape[0] != input_size[0] or img.shape[1] != input_size[1]:\n",
    "        input_img_resized = cv2.resize(img, input_size)\n",
    "    \n",
    "    input_img_rgb = cv2.cvtColor(input_img_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_img_normalized = input_img_rgb / 255.0\n",
    "\n",
    "    input_tensor = input_img_normalized.transpose(2, 0, 1).astype(np.float32)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "def post_process(outputs):\n",
    "    # Example post-processing code, adjust according to your model's output format\n",
    "    boxes, scores, class_ids = outputs  # Split the output tensors if necessary\n",
    "\n",
    "    # Thresholding and NMS to remove unnecessary boxes\n",
    "    threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, threshold, nms_threshold)\n",
    "\n",
    "    # Extract the detected objects\n",
    "    detected_objects = []\n",
    "    for i in indices:\n",
    "        box = boxes[i[0]]\n",
    "        score = scores[i[0]]\n",
    "        class_id = class_ids[i[0]]\n",
    "        detected_objects.append((box, score, class_id))\n",
    "    \n",
    "    return detected_objects\n",
    "\n",
    "def visulize_objects(input_image, detected_objects):\n",
    "    # Draw the bounding boxes on the image\n",
    "    for box, score, class_id in detected_objects:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(input_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        label = f'{class_id}: {score:.2f}'\n",
    "        cv2.putText(input_image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('Detected Objects', input_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Detect Image:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)\n",
      "Latency: 0.07558226585388184\n",
      "FPS: 13.230616847783228\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./../runs/detect/train8/weights/best.onnx\"\n",
    "source_path = \"./../data/test/val_all_data-56-_jpg.rf.fd1cd988f8460e5e0f2f51399df2c348.jpg\"\n",
    "\n",
    "input_img = read_img(source_path, \"image\")\n",
    "print(input_img.shape)\n",
    "preprocessed_img = preprocessing(input_img.copy())\n",
    "\n",
    "# ort_session = ort.SessionOptions()\n",
    "\n",
    "# ort_session.intra_op_num_threads = 4\n",
    "# ort_session.execution_mode = ort.ExecutionMode.ORT_PARALLEL\n",
    "# ort_session.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "# ort_session.add_session_config_entry(\"session.intra_op.allow_spinning\", \"1\")\n",
    "\n",
    "# ort_session = ort.InferenceSession(model_path,  sess_options=ort_session, providers=['CPUExecutionProvider'])\n",
    "ort_session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = ort_session.run(None, {'images': preprocessed_img})\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Latency:\", (end_time - start_time))\n",
    "print(\"FPS:\", 1/(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Detect Video:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def draw_detections(self, img, box, score, class_id):\n",
    "        \"\"\"\n",
    "        Draws bounding boxes and labels on the input image based on the detected objects.\n",
    "\n",
    "        Args:\n",
    "            img: The input image to draw detections on.\n",
    "            box: Detected bounding box.\n",
    "            score: Corresponding detection score.\n",
    "            class_id: Class ID for the detected object.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the coordinates of the bounding box\n",
    "        x1, y1, w, h = box\n",
    "\n",
    "        # Retrieve the color for the class ID\n",
    "        color = self.color_palette[class_id]\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "        # Create the label text with class name and score\n",
    "        label = f\"{self.classes[class_id]}: {score:.2f}\"\n",
    "\n",
    "        # Calculate the dimensions of the label text\n",
    "        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "        # Calculate the position of the label text\n",
    "        label_x = x1\n",
    "        label_y = y1 - 10 if y1 - 10 > label_height else y1 + 10\n",
    "\n",
    "        # Draw a filled rectangle as the background for the label text\n",
    "        cv2.rectangle(\n",
    "            img, (label_x, label_y - label_height), (label_x + label_width, label_y + label_height), color, cv2.FILLED\n",
    "        )\n",
    "\n",
    "        # Draw the label text on the image\n",
    "        cv2.putText(img, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def postprocess(self, input_image, output):\n",
    "        \"\"\"\n",
    "        Performs post-processing on the model's output to extract bounding boxes, scores, and class IDs.\n",
    "\n",
    "        Args:\n",
    "            input_image (numpy.ndarray): The input image.\n",
    "            output (numpy.ndarray): The output of the model.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The input image with detections drawn on it.\n",
    "        \"\"\"\n",
    "\n",
    "        # Transpose and squeeze the output to match the expected shape\n",
    "        outputs = np.transpose(np.squeeze(output[0]))\n",
    "\n",
    "        # Get the number of rows in the outputs array\n",
    "        rows = outputs.shape[0]\n",
    "\n",
    "        # Lists to store the bounding boxes, scores, and class IDs of the detections\n",
    "        boxes = []\n",
    "        scores = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Calculate the scaling factors for the bounding box coordinates\n",
    "        x_factor = self.img_width / self.input_width\n",
    "        y_factor = self.img_height / self.input_height\n",
    "\n",
    "        # Iterate over each row in the outputs array\n",
    "        for i in range(rows):\n",
    "            # Extract the class scores from the current row\n",
    "            classes_scores = outputs[i][4:]\n",
    "\n",
    "            # Find the maximum score among the class scores\n",
    "            max_score = np.amax(classes_scores)\n",
    "\n",
    "            # If the maximum score is above the confidence threshold\n",
    "            if max_score >= self.confidence_thres:\n",
    "                # Get the class ID with the highest score\n",
    "                class_id = np.argmax(classes_scores)\n",
    "\n",
    "                # Extract the bounding box coordinates from the current row\n",
    "                x, y, w, h = outputs[i][0], outputs[i][1], outputs[i][2], outputs[i][3]\n",
    "\n",
    "                # Calculate the scaled coordinates of the bounding box\n",
    "                left = int((x - w / 2) * x_factor)\n",
    "                top = int((y - h / 2) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "\n",
    "                # Add the class ID, score, and box coordinates to the respective lists\n",
    "                class_ids.append(class_id)\n",
    "                scores.append(max_score)\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "        # Apply non-maximum suppression to filter out overlapping bounding boxes\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, scores, self.confidence_thres, self.iou_thres)\n",
    "\n",
    "        # Iterate over the selected indices after non-maximum suppression\n",
    "        for i in indices:\n",
    "            # Get the box, score, and class ID corresponding to the index\n",
    "            box = boxes[i]\n",
    "            score = scores[i]\n",
    "            class_id = class_ids[i]\n",
    "\n",
    "            # Draw the detection on the input image\n",
    "            self.draw_detections(input_image, box, score, class_id)\n",
    "\n",
    "        # Return the modified input image\n",
    "        return input_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
